\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{pruning_web}
\citation{pruning_arxiv}
\citation{understanding}
\citation{tensorflow2015-whitepaper}
\@writefile{toc}{\contentsline {section}{Tartalmi \IeC {\"o}sszefoglal\IeC {\'o} (content summary in Hungarian)}{4}{chapter*.2}}
\@writefile{toc}{\contentsline {section}{Task proposal}{5}{chapter*.3}}
\citation{pruning_web}
\citation{pruning_arxiv}
\citation{understanding}
\citation{tensorflow2015-whitepaper}
\@writefile{toc}{\contentsline {section}{Content summary}{6}{chapter*.4}}
\citation{applications}
\@writefile{toc}{\contentsline {section}{Introduction}{7}{chapter*.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Technical overview}{9}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Minimal fully convolutional networks}{9}{section.1.1}}
\citation{applications}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Edge detection}{10}{section.1.2}}
\citation{sobel}
\citation{canny}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Conventional algorithmic edge detectors}{11}{subsection.1.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Using the detectors}{11}{subsection.1.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Tools}{12}{section.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Software}{12}{subsection.1.3.1}}
\newlabel{cudnn}{{1.3.1}{13}{Software}{subsection.1.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Hardware}{13}{subsection.1.3.2}}
\citation{pascal-voc-2012}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Implementation}{14}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Code structure}{14}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Preparing the input images}{14}{section.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Network structure}{15}{section.2.3}}
\citation{netscope}
\citation{trunc}
\citation{relu}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The basic structure of the network\relax }}{16}{figure.caption.6}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{net}{{2.1}{16}{The basic structure of the network\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}The objective function and output}{16}{subsection.2.3.1}}
\citation{adam}
\citation{sgd}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Training and error back-propagation}{18}{subsection.2.3.2}}
\newlabel{train}{{2.3.2}{18}{Training and error back-propagation}{subsection.2.3.2}{}}
\citation{nondet1}
\citation{nondet2}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Minimization}{19}{section.2.4}}
\newlabel{min}{{2.4}{19}{Minimization}{section.2.4}{}}
\citation{adam}
\@writefile{toc}{\contentsline {subsubsection}{Neglecting neurons}{20}{section*.7}}
\@writefile{toc}{\contentsline {subsubsection}{Freezing neurons}{21}{section*.8}}
\@writefile{toc}{\contentsline {subsubsection}{Reinitializing neurons}{21}{section*.9}}
\@writefile{toc}{\contentsline {subsubsection}{Stepping back}{21}{section*.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Testing the worth of a neuron}{21}{subsection.2.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}The minimization process}{22}{subsection.2.4.2}}
\newlabel{thresholds}{{2.4.2}{22}{The minimization process}{subsection.2.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Selection}{23}{subsection.2.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Flowchart of the minimization process\relax }}{23}{figure.caption.11}}
\newlabel{flow}{{2.2}{23}{Flowchart of the minimization process\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{Cosine similarity}{23}{section*.12}}
\@writefile{toc}{\contentsline {subsubsection}{Naive selection strategies}{24}{section*.13}}
\citation{sobel}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Metrics}{25}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Universal Image Quality Index}{25}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Visualization}{25}{section.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Mask visualizations, rows on the picture correspond to layers in the network. The first row represents the masks in the first layer. Three groups of five masks from the second layer are omitted.\relax }}{26}{figure.caption.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces An input and ground truth image\relax }}{26}{figure.caption.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Output after a few iterations and after convergence\relax }}{26}{figure.caption.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Intermediate outputs\relax }}{27}{figure.caption.16}}
\citation{prs}
\citation{knd}
\citation{spr}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results}{28}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Mask correlations}{28}{section.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces The minimum, maximum, standard deviance, mean and median of the cosine similarities and their absolute values are compared against the relative loss in score and best achieved score after disabling, using the Pearson, Kendall and Spearman correlation coefficients\relax }}{29}{table.caption.17}}
\newlabel{correlations}{{4.1}{29}{The minimum, maximum, standard deviance, mean and median of the cosine similarities and their absolute values are compared against the relative loss in score and best achieved score after disabling, using the Pearson, Kendall and Spearman correlation coefficients\relax }{table.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Plotting the scores}{29}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Plots displaying the percentage drop and gain in score for various layers. The right column only shows scores that are results of an optimal mask selection.\relax }}{30}{figure.caption.18}}
\newlabel{plots}{{4.1}{30}{Plots displaying the percentage drop and gain in score for various layers. The right column only shows scores that are results of an optimal mask selection.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Minimization strategy charts}{31}{section.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Results of the minimization with specific thresholds and strategies\relax }}{32}{figure.caption.19}}
\newlabel{fin}{{4.2}{32}{Results of the minimization with specific thresholds and strategies\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{33}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\ }
\@writefile{toc}{\contentsline {section}{Statement}{34}{chapter*.20}}
\bibdata{references}
\@writefile{toc}{\contentsline {section}{Acknowledgments}{35}{chapter*.21}}
\bibcite{pruning_web}{1}
\bibcite{pruning_arxiv}{2}
\bibcite{understanding}{3}
\bibcite{tensorflow2015-whitepaper}{4}
\bibcite{applications}{5}
\bibcite{sobel}{6}
\bibcite{canny}{7}
\bibcite{pascal-voc-2012}{8}
\bibcite{netscope}{9}
\bibcite{trunc}{10}
\bibcite{relu}{11}
\bibcite{adam}{12}
\bibcite{sgd}{13}
\bibcite{nondet1}{14}
\bibcite{nondet2}{15}
\bibcite{prs}{16}
\bibcite{knd}{17}
\bibcite{spr}{18}
\bibstyle{unsrt}
